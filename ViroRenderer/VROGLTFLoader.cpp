//
//  VROGLTFLoader.cpp
//  ViroRenderer
//
//  Copyright Â© 2017 Viro Media. All rights reserved.
//
//  Permission is hereby granted, free of charge, to any person obtaining
//  a copy of this software and associated documentation files (the
//  "Software"), to deal in the Software without restriction, including
//  without limitation the rights to use, copy, modify, merge, publish,
//  distribute, sublicense, and/or sell copies of the Software, and to
//  permit persons to whom the Software is furnished to do so, subject to
//  the following conditions:
//
//  The above copyright notice and this permission notice shall be included
//  in all copies or substantial portions of the Software.
//
//  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
//  EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
//  MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
//  IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
//  CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
//  TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
//  SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

#define TINYGLTF_IMPLEMENTATION 1
#define TINYGLTF_NO_STB_IMAGE_WRITE 1
#define TINYGLTF_NO_STB_IMAGE 1

#include "VROGLTFLoader.h"
#include "tiny_gltf.h"
#include "VROLog.h"
#include "VROPlatformUtil.h"
#include "VRONode.h"
#include "VROByteBuffer.h"
#include "VROGeometry.h"
#include "VROMaterial.h"
#include "VROBox.h"
#include "VROGeometryUtil.h"
#include "VROSurface.h"
#include "VROTestUtil.h"
#include "VROCompress.h"
#include "VROModelIOUtil.h"
#include "VROBone.h"
#include "VROKeyframeAnimation.h"
#include "VROSkeletalAnimation.h"
#include "VROSkeleton.h"
#include "VROBoneUBO.h"
#include "VROLog.h"
#include "VROShaderFactory.h"
#include "VROShaderModifier.h"
#include "VROShaderProgram.h"
#include "VROMorpher.h"

static std::string kVROGLTFInputSamplerKey = "timeInput";
std::map<std::string, std::shared_ptr<VROVertexBuffer>> VROGLTFLoader::_dataCache;
std::map<std::string, std::shared_ptr<VROTexture>> VROGLTFLoader::_textureCache;
std::map<int, std::shared_ptr<VROSkeleton>> VROGLTFLoader::_skinIndexToSkeleton;
std::map<int, std::map<int, std::vector<std::shared_ptr<VROKeyframeAnimation>>>> VROGLTFLoader::_nodeKeyFrameAnims;
std::map<int, std::vector<std::shared_ptr<VROSkeletalAnimation>>> VROGLTFLoader::_skinSkeletalAnims;
std::map<int, std::shared_ptr<VROSkinner>> VROGLTFLoader::_skinMap;

// An map of all skinner joint index to its corresponding node index (provided by tinygLTF).
std::map<int, std::map<int,int>> VROGLTFLoader::_skinIndexToJointNodeIndex;

// An map of all skinner joint index to its skinner child joint indexes (Not Nodes).
// Note: the first joint index at 0 is not necessairly the root joint. This is only the
// order of which the inverse bind data is provided in the gLTF JSON structure.
std::map<int, std::map<int,std::vector<int>>> VROGLTFLoader::_skinIndexToJointChildJoints;

// An map of all root skeleton joint indexes.
std::map<int, int> VROGLTFLoader::_skinIndexToSkeletonRootJoint;

static int getTypeSize(GLTFType type) {
    switch (type) {
        case GLTFType::Scalar: return 1;
        case GLTFType::Vec2: return 2;
        case GLTFType::Vec3: return 3;
        case GLTFType::Vec4: return 4;
        case GLTFType::Mat2: return 4;
        case GLTFType::Mat3: return 9;
        case GLTFType::Mat4: return 16;
        default: pabort();
    }
}

static int getComponentTypeSize(GLTFTypeComponent type) {
    switch (type) {
        case GLTFTypeComponent::Byte: return 1;
        case GLTFTypeComponent::UnsignedByte: return 1;
        case GLTFTypeComponent::Short: return 2;
        case GLTFTypeComponent::UnsignedShort: return 2;
        case GLTFTypeComponent::UnsignedInt: return 4;
        case GLTFTypeComponent::Float: return 4;
        default: pabort();
    }
}

VROGeometrySourceSemantic VROGLTFLoader::getGeometryAttribute(std::string name) {
    if (VROStringUtil::strcmpinsensitive(name, "POSITION")) {
        return VROGeometrySourceSemantic::Vertex;
    } else if (VROStringUtil::strcmpinsensitive(name, "NORMAL")) {
        return VROGeometrySourceSemantic::Normal;
    } else if (VROStringUtil::strcmpinsensitive(name, "TANGENT")) {
        return VROGeometrySourceSemantic::Tangent;
    } else if (VROStringUtil::strcmpinsensitive(name, "TEXCOORD_0")) {
        return VROGeometrySourceSemantic::Texcoord;
    } else if (VROStringUtil::strcmpinsensitive(name, "COLOR_0")) {
        return VROGeometrySourceSemantic::Color;
    } else if (VROStringUtil::strcmpinsensitive(name, "JOINTS_0")) {
        return VROGeometrySourceSemantic::BoneIndices;
    } else if (VROStringUtil::strcmpinsensitive(name, "WEIGHTS_0")) {
        return VROGeometrySourceSemantic::BoneWeights;
    } else {
        pwarn("Attempted to parse an unknown geometry attribute: %s", name.c_str());
    }
    return VROGeometrySourceSemantic::Invalid;
}

bool VROGLTFLoader::getComponentType(const tinygltf::Accessor &gAccessor, GLTFTypeComponent &typeComponent) {
    switch (gAccessor.componentType) {
        case TINYGLTF_COMPONENT_TYPE_BYTE:
            typeComponent = GLTFTypeComponent::Byte;
            break;
        case TINYGLTF_COMPONENT_TYPE_UNSIGNED_BYTE:
            typeComponent = GLTFTypeComponent::UnsignedByte;
            break;
        case TINYGLTF_COMPONENT_TYPE_SHORT:
            typeComponent = GLTFTypeComponent::Short;
            break;
        case TINYGLTF_COMPONENT_TYPE_UNSIGNED_SHORT:
            typeComponent = GLTFTypeComponent::UnsignedShort;
            break;
        case TINYGLTF_COMPONENT_TYPE_UNSIGNED_INT:
            typeComponent = GLTFTypeComponent::UnsignedInt;
            break;
        case TINYGLTF_COMPONENT_TYPE_FLOAT:
            typeComponent = GLTFTypeComponent::Float;
            break;
        default:
            perr("Unsupported Component type was provided to the GLTF Loader!");
            return false;
    }
    return true;
}

bool VROGLTFLoader::getComponent(const tinygltf::Accessor &gAccessor, GLTFType &type) {
    switch (gAccessor.type) {
        case TINYGLTF_TYPE_SCALAR:
            type = GLTFType::Scalar;
            break;
        case TINYGLTF_TYPE_VEC2:
            type = GLTFType::Vec2;
            break;
        case TINYGLTF_TYPE_VEC3:
            type = GLTFType::Vec3;
            break;
        case TINYGLTF_TYPE_VEC4:
            type = GLTFType::Vec4;
            break;
        case TINYGLTF_TYPE_MAT2:
            type = GLTFType::Mat2;
            break;
        case TINYGLTF_TYPE_MAT3:
            type = GLTFType::Mat3;
            break;
        case TINYGLTF_TYPE_MAT4:
            type = GLTFType::Mat4;
            break;
        default:
            perr("Unsupported Type was provided to the GLTF Loader!");
            return false;
    }
    return true;
}

bool VROGLTFLoader::getPrimitiveType(int mode, VROGeometryPrimitiveType &type) {
    switch (mode) {
        case TINYGLTF_MODE_LINE:
            type = VROGeometryPrimitiveType::Line;
            break;
        case TINYGLTF_MODE_POINTS:
            type = VROGeometryPrimitiveType::Point;
            break;
        case TINYGLTF_MODE_TRIANGLES:
            type = VROGeometryPrimitiveType::Triangle;
            break;
        case TINYGLTF_MODE_TRIANGLE_STRIP:
            type = VROGeometryPrimitiveType::TriangleStrip;
            break;
        case TINYGLTF_MODE_LINE_LOOP:
            // TODO VIRO-3686: Add support for additional primitive modes.
            perr("GLTF Mode LINE_LOOP primitive is not yet supported!");
            return false;
        case TINYGLTF_MODE_TRIANGLE_FAN:
            // TODO VIRO-3686: Add support for additional primitive modes.
            perr("GLTF Mode TRIANGLE_FAN primitive is not yet supported!");
            return false;
        default:
            perr("Unsupported GLTF primitive type provided for this model.");
            return false;
    }
    return true;
}

VROFilterMode VROGLTFLoader::getFilterMode(int mode) {
    switch(mode) {
        case TINYGLTF_TEXTURE_FILTER_NEAREST:
            //choose 1 pixel from the biggest mip
            return VROFilterMode::Nearest;
        case TINYGLTF_TEXTURE_FILTER_LINEAR:
            //choose 4 pixels from the biggest mip and blend them
            return VROFilterMode ::Linear;
        case TINYGLTF_TEXTURE_FILTER_NEAREST_MIPMAP_NEAREST:
            // Behavior: Choose the best mip, then pick one pixel from that mip
            // TODO VIRO-3687: Add additional Sampler filter modes. Fallback to nearest for now.
            return VROFilterMode::Nearest;
        case TINYGLTF_TEXTURE_FILTER_LINEAR_MIPMAP_NEAREST:
            // Behavior: choose the best mip, then blend 4 pixels from that mip
            // TODO VIRO-3687: Add additional Sampler filter modes. Fallback to nearest for now.
            return VROFilterMode::Nearest;
        case TINYGLTF_TEXTURE_FILTER_NEAREST_MIPMAP_LINEAR:
            // Behavior: choose the best 2 mips, choose 1 pixel from each, blend them
            // TODO VIRO-3687: Add additional Sampler filter modes. Fallback to Linear for now.
            return VROFilterMode::Linear;
        case TINYGLTF_TEXTURE_FILTER_LINEAR_MIPMAP_LINEAR:
            // Behavior: choose the best 2 mips. choose 4 pixels from each, blend them
            // TODO VIRO-3687: Add additional Sampler filter modes. Fallback to Linear for now.
            return VROFilterMode::Linear;
        default:
            return VROFilterMode::Linear;
    }
}

VROWrapMode VROGLTFLoader::getWrappingMode(int mode) {
    switch(mode) {
        case TINYGLTF_TEXTURE_WRAP_CLAMP_TO_EDGE:
            return VROWrapMode ::ClampToBorder;
        case TINYGLTF_TEXTURE_WRAP_MIRRORED_REPEAT:
            return VROWrapMode::Mirror;
        case TINYGLTF_TEXTURE_WRAP_REPEAT:
            return VROWrapMode::Repeat;
        default:
            return VROWrapMode::Repeat;
    }
}

void VROGLTFLoader::loadGLTFFromResource(std::string gltfManifestFilePath, const std::map<std::string, std::string> overwriteResourceMap,
                                         VROResourceType resourceType, std::shared_ptr<VRONode> rootNode, bool isGLTFBinary,
                                         std::shared_ptr<VRODriver> driver, std::function<void(std::shared_ptr<VRONode>, bool)> onFinish) {
      // First, retrieve the main GLTF 'json manifest' file (either .gltf or .glb)
      VROModelIOUtil::retrieveResourceAsync(gltfManifestFilePath, resourceType,
                                            [gltfManifestFilePath, overwriteResourceMap, isGLTFBinary, rootNode, driver, onFinish]
                                            (std::string cachedFilePath, bool isTemp) {
                // Then use TinyGltf to parse the GTLF structure, and corresponding auxiliary resource files.
                VROPlatformDispatchAsyncBackground([gltfManifestFilePath, overwriteResourceMap, isGLTFBinary, cachedFilePath, rootNode, driver, onFinish] {
                    tinygltf::Model gModel;
                    tinygltf::TinyGLTF gLoader;
                    std::string err;

                    // If we've successfully retrieved the GLTF Manifest, start parsing the file with tinyGLTF.
                    bool ret = false;
                    if (isGLTFBinary) {
                        ret = gLoader.LoadBinaryFromFile(&gModel, &err, cachedFilePath, overwriteResourceMap);
                    } else {
                        ret = gLoader.LoadASCIIFromFile(&gModel, &err, cachedFilePath, gltfManifestFilePath, overwriteResourceMap);
                    }

                    // Fail fast if any errors were encountered.
                    if (!err.empty()) {
                        pwarn("Error when parsing GTLF manifest: %s", err.c_str());
                        onFinish(nullptr, false);
                        return;
                    }

                    if (!ret) {
                        pwarn("Failed to parse glTF manifest.");
                        onFinish(nullptr, false);
                        return;
                    }

                    // Ensure that we are only processing GLTF 2.0 models.
                    std::string version = gModel.asset.version;
                    if (VROStringUtil::toFloat(version) < 2) {
                        pwarn("Error parsing GLTF model: Only GLTF 2.0 models are supported!");
                        onFinish(nullptr, false);
                        return;
                    }

                    // Once the manifest has been parsed, start constructing our Viro 3D Model.
                    const tinygltf::Model &model = gModel;
                    VROPlatformDispatchAsyncRenderer([rootNode, model, driver, onFinish] {
                        clearCachedData();

                        // Process and cache skinner and skeletal data needed for skeletal animation
                        // and skinner geometry to be set later on our nodes.
                        if (!processSkinner(model)) {
                            perr("Error when processing the skinner of GLTF model!");
                            onFinish(nullptr, false);
                            return;
                        }

                        // Now generate our KeyFrame and skeletal animations and cache them to be
                        // set later on our nodes (when we iterate through the scene hierarchy).
                        if (!processAnimations(model)) {
                            pwarn("Error when processing animation data of the GLTF model!");
                            onFinish(nullptr, false);
                            return;
                        }

                        // Finally, iterate through gLTF model data and build out our VRONodes that
                        // represent our 3D Model scene, setting cached animations / skinners on
                        // those nodes along the way.
                        bool success = true;
                        std::shared_ptr<VRONode> gltfRootNode = std::make_shared<VRONode>();
                        for (const tinygltf::Scene &gScene : model.scenes) {
                            if (!processScene(model, gltfRootNode, gScene, driver)) {
                                success = false;
                                break;
                            }
                        }

                        for (auto &skeletonPair : _skinIndexToSkeleton) {
                            std::shared_ptr<VROSkinner> skin = _skinMap[skeletonPair.first];
                            skeletonPair.second->setSkinnerRootNode(skin->getSkinnerNode());
                        }

                        // Once we have processed the model, injected it into the scene.
                        injectGLTF(success ? gltfRootNode : nullptr, rootNode, driver, onFinish);

                        // Clean up our cached resources.
                        clearCachedData();
                    });
                });
            },
            [gltfManifestFilePath, rootNode, onFinish]() {
                // Else if we have failed to retrieve the GTLF file, notify delegates on failure
                perr("Failed to retrieve GTLF file: %s", gltfManifestFilePath.c_str());
                onFinish(rootNode, false);
            });
}

void VROGLTFLoader::clearCachedData() {
    _dataCache.clear();
    _textureCache.clear();
    _skinIndexToSkeleton.clear();
    _skinIndexToJointNodeIndex.clear();
    _skinIndexToJointChildJoints.clear();
    _skinMap.clear();
    _nodeKeyFrameAnims.clear();
    _skinSkeletalAnims.clear();
    _skinIndexToSkeletonRootJoint.clear();
}

bool VROGLTFLoader::processSkinner(const tinygltf::Model &model) {
    if (model.skins.size() == 0) {
        return true;
    }

    // Create a map of all known joints used for building a tree of the
    // skeletal bones in this model.
    std::map<int, std::map<int,int>> skinIndexToNodeJointIndexes;
    for (int skinIndex = 0; skinIndex < model.skins.size(); skinIndex ++) {
        tinygltf::Skin skin = model.skins[skinIndex];

        for (int jointIndex = 0; jointIndex < skin.joints.size(); jointIndex++) {
            int nodeIndexOfJoint = skin.joints[jointIndex];
            skinIndexToNodeJointIndexes[skinIndex][nodeIndexOfJoint] = jointIndex;
            _skinIndexToJointNodeIndex[skinIndex][jointIndex] = nodeIndexOfJoint;
        }
    }

    // Construct _skinIndexToJointChildJoints and skinIndexToJointParentJoint mappings
    // respectively - these effectively maps out the joints within the skeletal tree
    // by keeping track of a joint's pointer to both child and parent joints.
    std::map<int, std::map<int, int>> skinIndexToJointParentJoint;
    for (int skinIndex = 0; skinIndex < model.skins.size(); skinIndex ++) {
        tinygltf::Skin skin = model.skins[skinIndex];
        for (int jointIndex = 0; jointIndex < skin.joints.size(); jointIndex++) {

            // Grab the node index corresponding to this joint.
            int nodeIndex = _skinIndexToJointNodeIndex[skinIndex][jointIndex];

            // Then look up the node with the nodeIndex and grab it's child nodes.
            std::vector<int> childrenNodeIndex = model.nodes[nodeIndex].children;
            for (int childIndex : childrenNodeIndex) {
                // Skip if we have child indexes that are not a joint.
                if (skinIndexToNodeJointIndexes[skinIndex].find(childIndex) == skinIndexToNodeJointIndexes[skinIndex].end()) {
                    continue;
                }

                // For each of the child node index, get it's corresponding joint index.
                int subJointIndex = skinIndexToNodeJointIndexes[skinIndex][childIndex];

                // Parent the all childed joint with it's parent. Also create a reverse map
                // in skinIndexToJointParentJoint.
                _skinIndexToJointChildJoints[skinIndex][jointIndex].push_back(subJointIndex);
                skinIndexToJointParentJoint[skinIndex][subJointIndex] = jointIndex;
            }
        }
        
        // Save a reference to the root
        int nodeIndexOfSkeleton = skin.skeleton;
        if (nodeIndexOfSkeleton >= 0) {
            _skinIndexToSkeletonRootJoint[skinIndex] = skinIndexToNodeJointIndexes[skinIndex][nodeIndexOfSkeleton];
        } else {
            // Else grab the first item in the joint list and treat it as the root node.
            _skinIndexToSkeletonRootJoint[skinIndex] = 0;
        }
    }

    // Finally, use the joint tree to construct our VROSkeleton and VROSkinners.
    for (int skinIndex = 0; skinIndex < model.skins.size(); skinIndex ++) {
        tinygltf::Skin skin = model.skins[skinIndex];

        // Process the vec of inverse bind transforms (in the order of specific joints in the gLTF file).
        std::vector<VROMatrix4f> invBindTransformsOut;
        if (!processSkinnerInverseBindData(model, model.skins[skinIndex], invBindTransformsOut)) {
            pwarn("Failed to process Skinner");
            return false;
        }

        std::vector<std::shared_ptr<VROBone>> bones;
        int rootJoint = _skinIndexToSkeletonRootJoint[skinIndex];
        
        // Create a vec hiearachy of bones, starting at the root bone.
        for (int jointIndex = 0; jointIndex < skin.joints.size(); jointIndex++) {
            int parentJointIndex = skinIndexToJointParentJoint[skinIndex][jointIndex];
            if (jointIndex == rootJoint) {
                parentJointIndex = -1;
            }
            
            // TODO We need the bone local transform if we want layered animations to work with GLTF
            VROMatrix4f boneSpaceBindTransform = invBindTransformsOut[jointIndex];
            std::string name = "BoneIndex_" + VROStringUtil::toString(jointIndex);

            std::shared_ptr<VROBone> bone = std::make_shared<VROBone>(jointIndex,
                                                                      parentJointIndex,
                                                                      name,
                                                                      VROMatrix4f::identity(),
                                                                      boneSpaceBindTransform);
            bones.push_back(bone);
        }
        std::shared_ptr<VROSkeleton> skeleton = std::make_shared<VROSkeleton>(bones);
        _skinIndexToSkeleton[skinIndex] = skeleton;
        _skinMap[skinIndex] = std::shared_ptr<VROSkinner>(new VROSkinner(skeleton,
                                                   VROMatrix4f(),
                                                   invBindTransformsOut,
                                                   nullptr,
                                                   nullptr));
    }
    return true;
}

bool VROGLTFLoader::processAnimations(const tinygltf::Model &model) {
    if (model.animations.size() == 0) {
        return true;
    }

    /*
     In gLTF, model.animations contain an array of gLTF animations, and a single gLTF animation
     contains an array of gLTF "channels". A channel targets a node with the time and raw
     animation data. As such, we'll need to convert a single gLTF channel into a
     VROKeyframeAnimation to be then applied onto a node.

     Thus, we need to group gLTF animation data for easier parsing. We group as follows:
     - Map a gLTF animation to its corresponding node index.
     - And for each node index, map a vec of channels.

     This results in:
     <nodeIndex, <animationIndex, vec<channelIndexes>> nodeToAnimDataMap
    */

    std::map<int, std::map<int, std::vector<int>>> nodeToAnimDataMap;
    std::map<int, std::set<int>> animToNodeIndexMap;
    for (int animIndex = 0; animIndex < model.animations.size(); animIndex++) {
        tinygltf::Animation anim = model.animations[animIndex];

        // For each animation, grab the targeted node and its animation channel data.
        for (int cIndex = 0; cIndex < anim.channels.size(); cIndex++) {
            tinygltf::AnimationChannel channel = anim.channels[cIndex];
            nodeToAnimDataMap[channel.target_node][animIndex].push_back(cIndex);

            // Also save a reverse map of anim to nodeIndexes for skeletal animation processing.
            animToNodeIndexMap[animIndex].insert(channel.target_node);
        }
    }

    // Group all the node indexes associated with a given skin to be used for
    // skeletal animation processing.
    std::map<int, std::set<int>> skinToNodeMap;
    for (int skinIndex = 0; skinIndex < model.skins.size(); skinIndex ++) {
        tinygltf::Skin skin = model.skins[skinIndex];
        for (int jointIndex = 0; jointIndex < skin.joints.size(); jointIndex++) {
            skinToNodeMap[skinIndex].insert(skin.joints[jointIndex]);
        }
    }

    // For each animation, determine if it is a skeletalAnimation (gLTF doesn't tell us)
    // To do this, we assume that if an animation contains ANY of the nodes specified in a
    // skinner, it is treated automatically as a skeletalAnim.
    std::map<int, std::pair<int, std::vector<int>>> skeletalAnimToSkinToNodeMap;
    for (int animIndex = 0; animIndex < animToNodeIndexMap.size(); animIndex++) {
        for (int skinIndex = 0; skinIndex < skinToNodeMap.size(); skinIndex ++) {
            // Check to which joints are skeletal animations
            std::vector<int> animatedSkeletalJoint;
            for (auto i : skinToNodeMap[skinIndex]) {
                for (auto x : animToNodeIndexMap[animIndex]) {
                    if (i == x) {
                        animatedSkeletalJoint.push_back(i);
                    }
                }
            }

            if (animatedSkeletalJoint.size() > 0) {
                skeletalAnimToSkinToNodeMap[animIndex] = std::make_pair(skinIndex, animatedSkeletalJoint);
            }
        }
    }

    // For each animation channel in the gltf model, convert them into VROKeyframeAnimations
    // and cache them in _nodeKeyFrameAnims to be later set on a VRONode.
    if (!processKeyFrameAnimations(model, nodeToAnimDataMap)) {
        perr("Error when parsing key frame animations");
        return false;
    }

    // Finally also process skeletal animations, if any.
    processSkeletalAnimation(model, skeletalAnimToSkinToNodeMap);
    return true;
}

bool VROGLTFLoader::processKeyFrameAnimations(const tinygltf::Model &model,
                                             std::map<int, std::map<int, std::vector<int>>> &animatedNodes) {
    // First, iterate through all the affected animated nodes.
    for (auto const& animNode : animatedNodes) {
        std::map<int, std::vector<int>> animations = animNode.second;
        int nodeIndex = animNode.first;
        
        // Then iterate through all the animations for this node.
        for (auto const &anim : animations) {
            int animationIndex = anim.first;
            std::vector<int> channelsData = anim.second;

            // Then iterate through all the channel data for this animation
            // and create a corresponding VROKeyframeAnimation. Note that
            // we need to create a Keyframe animation for each channel as
            // they may have different sampler time durations.
            for (int channelIndex : channelsData) {
                std::shared_ptr<VROKeyframeAnimation> animation
                                    = convertChannelToKeyFrameAnimation(model,
                                                                        model.animations[animationIndex],
                                                                        channelIndex);
                if (animation == nullptr) {
                    return false;
                }

                // If no animation is given, set a default one with an index reference.
                std::string name = model.animations[anim.first].name;
                if (name.size() == 0) {
                    name = "animation_" + VROStringUtil::toString(animationIndex);
                }
                animation->setName(name);
                _nodeKeyFrameAnims[nodeIndex][anim.first].push_back(animation);
            }
        }
    }

    return true;
}

std::shared_ptr<VROKeyframeAnimation> VROGLTFLoader::convertChannelToKeyFrameAnimation(
        const tinygltf::Model &gModel,
        const tinygltf::Animation &anim,
        int targetedChannel) {
    // Process input key frames first to create our vector of KeyFrameAnimationFrames to populate
    // with animation data like Position, Rotation, Scaling.
    std::vector<std::unique_ptr<VROKeyframeAnimationFrame>> frames;
    tinygltf::AnimationChannel inputChannel = anim.channels[targetedChannel];
    tinygltf::AnimationSampler inputSampler = anim.samplers[inputChannel.sampler];
    if (!processRawChannelData(gModel, kVROGLTFInputSamplerKey, inputChannel.target_node, inputSampler, frames)) {
        return nullptr;
    }

    if (frames.size() == 0) {
        perror("Unable to properly parse Animation frames");
        return nullptr;
    }

    // Set the total duration of this keyframe animation, in seconds
    float duration = frames.back()->time;

    // Normalize the input key frame time (expected by Viro's animation system)
    for (int i = 0; i < frames.size(); i++) {
        frames[i]->time = frames[i]->time / duration;
    }

    // Grab the channel object from the given index, and process it's raw buffered data
    // into translation, scale or rotation for this keyframe animation.
    bool hasTranslation = false;
    bool hasRotation = false;
    bool hasScale = false;
    bool hasMorphWeights = false;
    tinygltf::AnimationChannel channel = anim.channels[targetedChannel];
    tinygltf::AnimationSampler gSampler = anim.samplers[channel.sampler];
    if (!processRawChannelData(gModel, channel.target_path, channel.target_node, gSampler, frames)) {
        perr("Failed to process channel index %s for gltf model!", channel.target_path.c_str());
        return nullptr;
    }

    if (VROStringUtil::strcmpinsensitive(channel.target_path, "translation")) {
        hasTranslation = true;
    } else if (VROStringUtil::strcmpinsensitive(channel.target_path, "scale")) {
        hasScale = true;
    } else if (VROStringUtil::strcmpinsensitive(channel.target_path, "rotation")) {
        hasRotation = true;
    }  else if (VROStringUtil::strcmpinsensitive(channel.target_path, "weights")) {
        hasMorphWeights = true;
    }

    return std::make_shared<VROKeyframeAnimation>(frames, duration, hasTranslation, hasRotation, hasScale, hasMorphWeights);
}

bool VROGLTFLoader::processRawChannelData(const tinygltf::Model &gModel,
                                          std::string channelProperty,
                                          int channelTarget,
                                          const tinygltf::AnimationSampler &channelSampler,
                                          std::vector<std::unique_ptr<VROKeyframeAnimationFrame>> &framesOut) {
    // TODO VIRO-3848: Support additional 3D Model Interpolation types
    if (!VROStringUtil::strcmpinsensitive(channelSampler.interpolation, "linear")) {
        pwarn("Viro does not currently support non-linear animations for gltf models.");
        return false;
    }

    // Grab the accessor that maps to a bufferView through which to access the data buffer
    // representing this channel's raw data.
    int accessorIndex = channelSampler.output;
    if (VROStringUtil::strcmpinsensitive(channelProperty, kVROGLTFInputSamplerKey)) {
        accessorIndex = channelSampler.input;
    }
    const tinygltf::Accessor &gDataAcessor = gModel.accessors[accessorIndex];
    GLTFTypeComponent gTypeComponent;
    GLTFType gType;
    if (!getComponentType(gDataAcessor, gTypeComponent) || !getComponent(gDataAcessor, gType)) {
        perr("Invalid Animation channel data provided!");
        return false;
    }

    // Since GLTF does not tell us which primitive the morph targets belong to,
    // we always grab the targets of the first primitive from the target node's mesh.
    int numberOfMorphTargets = 0;
    if (VROStringUtil::strcmpinsensitive(channelProperty, "weights")) {
        int meshIndex = gModel.nodes[channelTarget].mesh;
        if (gModel.meshes[meshIndex].primitives.size() <= 0) {
            perr("Missing morph targets needed for animation!");
            return false;
        }
        
        // Always assume that all primitives have the same amount of targets.
        numberOfMorphTargets = (int) gModel.meshes[meshIndex].primitives.front().targets.size();
    }

    // Calculate the byte stride size if none is provided from the BufferView.
    const tinygltf::BufferView &gIndiceBufferView = gModel.bufferViews[gDataAcessor.bufferView];
    size_t bufferViewStride = gIndiceBufferView.byteStride;
    if (bufferViewStride == 0) {
        int sizeOfSingleElement = getTypeSize(gType) * getComponentTypeSize(gTypeComponent);
        bufferViewStride = sizeOfSingleElement;
    }

    // Determine offsets and data sizes representing the 'window of data' in the buffer
    size_t elementCount = gDataAcessor.count;
    size_t dataOffset = gDataAcessor.byteOffset + gIndiceBufferView.byteOffset;
    size_t dataLength = elementCount * bufferViewStride;

    if (VROStringUtil::strcmpinsensitive(channelProperty, kVROGLTFInputSamplerKey)) {
        // A kVROGLTFInputSamplerKey channelProperty param is provided when creating new, empty
        // VROKeyFrameAnimations to be used for storing animation data.
        for (int i = 0; i < elementCount; i ++) {
            std::unique_ptr<VROKeyframeAnimationFrame> frame
                    = std::unique_ptr<VROKeyframeAnimationFrame>(new VROKeyframeAnimationFrame());
            framesOut.push_back(std::move(frame));
        }
    } else if (VROStringUtil::strcmpinsensitive(channelProperty, "weights")) {
        if ((elementCount != (framesOut.size() * numberOfMorphTargets))) {
            perr("Animation frame %s do not match number of morph keyframes %d, %d",
                 channelProperty.c_str(), (int) elementCount, (int) (framesOut.size() * numberOfMorphTargets));
            return false;
        }
    } else if (elementCount != framesOut.size()) {
        // Else if we are processing an output channel (animation data relating to key frames),
        // ensure that the size of the data aligns with the number of expected key frames.
        perr("Animation frame %s do not match number of keyframes %d, %d", channelProperty.c_str(), (int) elementCount, (int) framesOut.size());
        return false;
    }

    // Now process that buffer to produce the right output data.
    const tinygltf::Buffer &gBuffer = gModel.buffers[gIndiceBufferView.buffer];
    std::vector<float> tempVec;
    int morphIndex = 0;
    VROByteBuffer buffer((char *)gBuffer.data.data() + dataOffset, dataLength, false);
    for (int elementIndex = 0; elementIndex < elementCount; elementIndex++) {

        // Set the buffer position to begin at each element index - Ex: Each Vec4.
        buffer.setPosition(elementIndex * bufferViewStride);
        tempVec.clear();

        // For the current element, cycle through each of its float or type component
        // and convert them into a float through the math conversions required by gLTF.
        for (int componentCount = 0; componentCount < getTypeSize(gType); componentCount ++) {
            if (gTypeComponent == GLTFTypeComponent::Float) {
                float floatData = buffer.readFloat();
                tempVec.push_back(floatData);
            } else if (gTypeComponent == GLTFTypeComponent::UnsignedShort) {
                unsigned short uShortData = buffer.readUnsignedShort();
                float point = uShortData / 65535.0;
                tempVec.push_back(point);
            } else if (gTypeComponent == GLTFTypeComponent::Short) {
                short shortData = buffer.readShort();
                float point = std::max(shortData / 32767.0, -1.0);
                tempVec.push_back(point);
            } else if (gTypeComponent == GLTFTypeComponent::UnsignedByte) {
                unsigned uByteData = buffer.readUnsignedByte();
                float point = uByteData / 255.0;
                tempVec.push_back(point);
            } else if (gTypeComponent == GLTFTypeComponent::Byte) {
                signed char byteData = buffer.readByte();
                float point = std::max(byteData / 127.0, -1.0);
                tempVec.push_back(point);
            } else {
                pwarn("Invalid element type in Animation Accessor Data: %d", gTypeComponent);
                return false;
            }
        }

        if (VROStringUtil::strcmpinsensitive(channelProperty, "translation") && tempVec.size() == 3) {
            framesOut[elementIndex]->translation = {tempVec[0], tempVec[1], tempVec[2]};
        } else if (VROStringUtil::strcmpinsensitive(channelProperty, "rotation")&& tempVec.size() == 4) {
            framesOut[elementIndex]->rotation = {tempVec[0], tempVec[1], tempVec[2], tempVec[3]};
        } else if (VROStringUtil::strcmpinsensitive(channelProperty, "scale")&& tempVec.size() == 3) {
            framesOut[elementIndex]->scale = {tempVec[0], tempVec[1], tempVec[2]};
        } else if (VROStringUtil::strcmpinsensitive(channelProperty, kVROGLTFInputSamplerKey)) {
            framesOut[elementIndex]->time = tempVec[0];
        } else if (VROStringUtil::strcmpinsensitive(channelProperty, "weights")) {
            // GLTF only supports animating one primitive's morph target on a node at a time
            // and as such we process only a single morph target per channel.
            int meshIndex = gModel.nodes[channelTarget].mesh;
            std::string key = getMorphTargetName(gModel,
                                                 gModel.meshes[meshIndex].primitives.front(),
                                                 morphIndex);
            framesOut[elementIndex/numberOfMorphTargets]->morphWeights[key] = tempVec[0];

            // The weights for all morph targets are tightly interleaved. As such, use
            // morphIndex to increment, track and accumulate all morph data for this frame.
            // Once we have hit the numberOfMorphTargets, we reset this to 0 to move
            // onto the next frame containing the new set of morph data.
            morphIndex ++;
            if (morphIndex >= numberOfMorphTargets) {
                morphIndex = 0;
            }
        } else {
            pwarn("Invalid target path %s with data size %d provided for gLTF.", channelProperty.c_str(), (int) tempVec.size());
            return false;
        }
    }
    return true;
}

bool VROGLTFLoader::processSkeletalAnimation(const tinygltf::Model &model,
                                     std::map<int, std::pair<int, std::vector<int>>> &skeletalAnimToSkinToNodeMap) {
    if (skeletalAnimToSkinToNodeMap.size() == 0) {
        return true;
    }

    flattenSkeletalKeyframeAnimations(skeletalAnimToSkinToNodeMap);

    // First, iterate through each skeletal animation that is associated with each
    // skinner in the scene. Also assume that an animation can only move a single
    // skinner at a time (multi-skinner-animation for a single animation is not supported)
    for (auto &animToSkinToNodePair : skeletalAnimToSkinToNodeMap) {
        int skinIndex = animToSkinToNodePair.second.first;
        int skeletalAnimationIndex = animToSkinToNodePair.first;
        
        int rootJointIndexForSkin = _skinIndexToSkeletonRootJoint[skinIndex];
        int animatedNodeIndexFirst = _skinIndexToJointNodeIndex[skinIndex][rootJointIndexForSkin];

        // For the current skeletal animation, grab first joint/Node, and then grab
        // it's vec of VROKeyframeAnimations. (This is because at this point, a given
        // joint can have different animated properties with different input time samples).
        std::vector<std::shared_ptr<VROKeyframeAnimation>> animatedChannels;
        animatedChannels = _nodeKeyFrameAnims[animatedNodeIndexFirst][skeletalAnimationIndex];

        // If there are no animations for the root node, keep iterating until we find one.
        // We are assuming here that the animation for this skinner has the same
        // duration and keyframe intervals for all of its bones.
        if (animatedChannels.size() == 0) {
            std::vector<int> intersectingAnimatedJoints = animToSkinToNodePair.second.second;
            for (auto jointIndex : intersectingAnimatedJoints) {
                animatedChannels = _nodeKeyFrameAnims[jointIndex][skeletalAnimationIndex];
                if (animatedChannels.size() != 0) {
                    break;
                }
            }
        }

        // For each animatedProperty, construct a corresponding skeletal animation.
        if (animatedChannels.size() > 1) {
            pwarn("Viro: Animations with multi-time interval inputs are not yet supported!");
        } else if (animatedChannels.size() == 0) {
            pwarn("Viro: No animations found!");
            return true;
        }

        // TODO: There can be cases where there are multiple animated properties with different
        // keyframe interval durations (for example, translation animates at a different speed
        // than rotation, towards the same duration, for the same animation). Thus, in this case
        // we'll need to combine the different skeletal animations into a layered skeletal
        // animation. For the moment, we simply not include the data (only consider the first index)
        int channelIndex = 0;

        // First, create a set of skeletal Frames, populate them with empty key frames (with time stamp data)
        std::shared_ptr<VROKeyframeAnimation> keyFrameAnim = animatedChannels[channelIndex];
        float totalDuration = keyFrameAnim->getDuration();
        std::vector<std::unique_ptr<VROSkeletalAnimationFrame>> skeletalFrames;
        const std::vector<std::unique_ptr<VROKeyframeAnimationFrame>> &frames = keyFrameAnim->getFrames();
        for (int i = 0; i < frames.size(); i++) {
            std::unique_ptr<VROSkeletalAnimationFrame> skeletalFrame = std::unique_ptr<VROSkeletalAnimationFrame>(new VROSkeletalAnimationFrame());
            skeletalFrame->time = frames[i]->time;

            // TODO We should support the non-legacy (concatenated transform) format
            skeletalFrame->boneTransformsLegacy = true;
            skeletalFrames.push_back(std::move(skeletalFrame));
        }

        // Then iterate through each frame and populate them with the computed transform for each joint/bone.
        std::shared_ptr<VROSkeleton> currentSkeleton = _skinIndexToSkeleton[skinIndex];
        std::shared_ptr<VROSkinner> currentSkinner = _skinMap[skinIndex];
        for (int i = 0; i < frames.size(); i++) {
            std::map<int, VROMatrix4f> computedAnimatedJointTrans;
            if (!processSkeletalTransformsForFrame(model, skinIndex, skeletalAnimationIndex, channelIndex, i, 0,
                                                       computedAnimatedJointTrans)) {
                return false;
            }

            // Then, for each joint, move the transform the computed joint back into bone space
            // and save that into the skeletalFrames for the animation.
            for (int jointI = 0; jointI < computedAnimatedJointTrans.size(); jointI++) {
                VROMatrix4f invBind = _skinMap[skinIndex]->getSkeleton()->getBone(jointI)->getBindTransform();
                VROMatrix4f computedAnimatedBoneTrans = invBind.multiply(computedAnimatedJointTrans[jointI]);
                skeletalFrames[i]->boneIndices.push_back(jointI);
                skeletalFrames[i]->boneTransforms.push_back(computedAnimatedBoneTrans);
            }
        }

        // Finally construct our skeletal animation
        std::shared_ptr<VROSkeletalAnimation> skeletalAnimation
                = std::make_shared<VROSkeletalAnimation>(currentSkinner, skeletalFrames, totalDuration);
        skeletalAnimation->setName(keyFrameAnim->getName());
        _skinSkeletalAnims[skinIndex].push_back(skeletalAnimation);

        // Remove any KeyFrameAnimations that were "turned into" and used for skeletal animations.
        // If an animation is on a skinner node, it is always treated as a skeletal animation.
        for (auto &jointNode : _skinIndexToJointNodeIndex[skinIndex]) {
            int nodeIndex = jointNode.second;
            _nodeKeyFrameAnims[nodeIndex][skeletalAnimationIndex].clear();
        }
    }
    return true;
}

/*

 TODO VIRO-5741: Remove this once we have updated GLTF support for layered skeletal animations.

 In GLTF, a single joint can have multiple VROKeyframeAnimations with different durations
 and input times, for the same animation. This is can still be supported with layered
 skeletal animations played in parallel, but we don't yet support that with GLTF models
 because of the usage of legacy binding transforms.

 As a *temporary* mitigation, we simply group VROKeyframeAnimations with the same input time data
 (same duration and keyframe intervals), and flatten them into a single VROKeyframeAnimation
 to be used for skeletal animations (thus no skeletal layering is needed). This has two caveats:

 - Outlying VROKeyframeAnimations that do not match the same input time data are ignored,
   as there is no way to merge animations with different time data.

 - If we encounter multiple Keyframe animations with identical animated attributes (say if two
   keyframe animations were modifying rotational properties at the same time), only the latest
   one is used.

 */
void VROGLTFLoader::flattenSkeletalKeyframeAnimations(std::map<int, std::pair<int, std::vector<int>>> &skeletalAnimToNodeSkinPair) {
    // Iterate through each skeletal animation and flattern them if possible.
    for (auto &animToSkinToNodePair : skeletalAnimToNodeSkinPair) {
        int skeletalAnimationIndex = animToSkinToNodePair.first;

        // Reset chosen input time data used for flattening animations.
        float chosenDuration = -1;
        int chosenNumberOfFrames = -1;

        // Iterate through all the skinner nodes in the skeletal animation
        // and for each node examine its keyframe animations.
        for (auto &nodeIndex : animToSkinToNodePair.second.second) {

            // Skip if there's no animation for this node in the skeleton.
            if (_nodeKeyFrameAnims[nodeIndex][skeletalAnimationIndex].size() == 0) {
                continue;
            }

            // Set the duration and keyframes for this skeletal animation if we haven't yet done so.
            std::vector<std::shared_ptr<VROKeyframeAnimation>> &keyframeAnimations = _nodeKeyFrameAnims[nodeIndex][skeletalAnimationIndex];
            if (chosenDuration == -1) {
                chosenDuration = keyframeAnimations.front()->getDuration();
            }

            if (chosenNumberOfFrames == -1) {
                chosenNumberOfFrames = (int) keyframeAnimations.front()->getFrames().size();
            }

            // Remove the keyframe animations for this node with different time input data
            // (different animation duration and keyframe count).
            keyframeAnimations.erase(std::remove_if(
                            keyframeAnimations.begin(),
                            keyframeAnimations.end(),
                            [chosenDuration, chosenNumberOfFrames](const std::shared_ptr<VROKeyframeAnimation> & o) {
                                pwarn("Viro: Removing mis-matching animation - layered skeletal animations not yet supported for gLTF.");
                                return o->getDuration() != chosenDuration || o->getFrames().size() != chosenNumberOfFrames;}),
                            keyframeAnimations.end());

            // If there's only one keyframeAnimation for this joint, there's no need to
            // attempt flattening - simply continue.
            if (keyframeAnimations.size() <= 1) {
                continue;
            }

            // Else, at this point all keyframeAnimations for this node should have the same
            // time input data (same duration and keyframe count). Now we attempt to
            // flatten the keyframeAnimations into a single one with combined transforms.
            std::vector<std::unique_ptr<VROKeyframeAnimationFrame>> flattenedKeyFrames;
            const std::vector<std::unique_ptr<VROKeyframeAnimationFrame>> &currFrames = keyframeAnimations.front()->getFrames();

            // First, initialize flattenedKeyFrames with the input time data.
            for (int f = 0; f < currFrames.size(); f ++) {
                std::unique_ptr<VROKeyframeAnimationFrame> animatedFrame
                    = std::unique_ptr<VROKeyframeAnimationFrame>(new VROKeyframeAnimationFrame());
                animatedFrame->time = currFrames[f]->time;
                flattenedKeyFrames.push_back(std::move(animatedFrame));
            }

            // Then iterate through all the animated properties, and for each keyframe within them
            // combine the properties into the final flattenedKeyFrames.
            bool hasTrans, hasScale, hasRotation, hasMorph = false;
            for (int channelIndex = 0; channelIndex < keyframeAnimations.size(); channelIndex++) {
                for (int keyFrameTime = 0; keyFrameTime < flattenedKeyFrames.size(); keyFrameTime++) {
                    const std::vector<std::unique_ptr<VROKeyframeAnimationFrame>> &currFrames = keyframeAnimations[channelIndex]->getFrames();

                    if (keyframeAnimations[channelIndex]->_hasTranslation) {
                        hasTrans = true;
                        flattenedKeyFrames[keyFrameTime]->translation = currFrames[keyFrameTime]->translation;
                    } else if (keyframeAnimations[channelIndex]->_hasScale) {
                        hasScale = true;
                        flattenedKeyFrames[keyFrameTime]->scale = currFrames[keyFrameTime]->scale;
                    } else if (keyframeAnimations[channelIndex]->_hasRotation) {
                        hasRotation = true;
                        flattenedKeyFrames[keyFrameTime]->rotation = currFrames[keyFrameTime]->rotation;
                    } else if (keyframeAnimations[channelIndex]->_hasMorphWeights) {
                        hasMorph = true;
                        flattenedKeyFrames[keyFrameTime]->morphWeights = currFrames[keyFrameTime]->morphWeights;
                    }
                }
            }

            // Finally construct the flattened keyframe animation.
            float duration = keyframeAnimations.front()->getDuration();
            std::shared_ptr<VROKeyframeAnimation> flattenedKeyframeAnimation
                = std::make_shared<VROKeyframeAnimation>(flattenedKeyFrames,
                        duration,
                        hasTrans,
                        hasRotation,
                        hasScale,
                        hasMorph);
            flattenedKeyframeAnimation->setName(keyframeAnimations.front()->getName());
            keyframeAnimations.clear();
            keyframeAnimations.push_back(flattenedKeyframeAnimation);
        }
    }
}

bool VROGLTFLoader::processSkeletalTransformsForFrame(const tinygltf::Model &gModel,
                                                      int skin,
                                                      int animationIndex,
                                                      int subAnimPropertyIndex,
                                                      int keyFrameTime,
                                                      int currentJointIndex,
                                                      std::map<int, VROMatrix4f> &transformsOut) {
    // If we are at the root, process its transform to be cascaded down the model's scene tree.
    int childNodeIndex = _skinIndexToJointNodeIndex[skin][0];

    if (currentJointIndex == 0) {
        if (_nodeKeyFrameAnims[childNodeIndex][animationIndex].size() == 0) {

            // If the there are no animations configured for this bone, simply get the model's
            // original local transform.
            transformsOut[0] = getTransformOfNode(gModel, childNodeIndex);
        } else {
            std::shared_ptr<VROKeyframeAnimation> animation = _nodeKeyFrameAnims[childNodeIndex][animationIndex].at(subAnimPropertyIndex);
            const std::vector<std::unique_ptr<VROKeyframeAnimationFrame>> &frames = animation->getFrames();
            VROMatrix4f localTransform;
            localTransform.toIdentity();
            if (animation->_hasScale) {
                localTransform.scale(frames[keyFrameTime]->scale.x,
                                     frames[keyFrameTime]->scale.y,
                                     frames[keyFrameTime]->scale.z);
            }

            if (animation->_hasRotation) {
                localTransform = frames[keyFrameTime]->rotation.getMatrix() * localTransform;
            }

            if (animation->_hasTranslation) {
                localTransform.translate(frames[keyFrameTime]->translation);
            }
            transformsOut[0] = localTransform;
        }
    }

    // Grab the transform of the current joint to be cascaded and multiplied on the child.
    VROMatrix4f currentMatrix = transformsOut[currentJointIndex];

    // Grab all the child joints for this current joint.
    std::vector<int> childJoints = _skinIndexToJointChildJoints[skin][currentJointIndex];
    for (int childJointIndex : childJoints) {
        // Get the actual node index for the child joint Index and it's animation to set.
        int childNodeIndex = _skinIndexToJointNodeIndex[skin][childJointIndex];

        VROMatrix4f localTransform = VROMatrix4f::identity();
        if (_nodeKeyFrameAnims[childNodeIndex][animationIndex].size() == 0) {
            localTransform = getTransformOfNode(gModel, childNodeIndex);
        } else {
            // Grab the animation transform of the current keyFrame
            std::shared_ptr<VROKeyframeAnimation> animation = _nodeKeyFrameAnims[childNodeIndex][animationIndex].at(subAnimPropertyIndex);
            const std::vector<std::unique_ptr<VROKeyframeAnimationFrame>> &frames = animation->getFrames();
            if (animation->_hasScale) {
                localTransform.scale(frames[keyFrameTime]->scale.x,
                                     frames[keyFrameTime]->scale.y,
                                     frames[keyFrameTime]->scale.z);
            }
            if (animation->_hasRotation) {
                localTransform = frames[keyFrameTime]->rotation.getMatrix() * localTransform;
            }

            if (animation->_hasTranslation) {
                localTransform.translate(frames[keyFrameTime]->translation);
            }
        }
        
        // Now cascade and compute the actual world computed transform in model space, save it in transformsOut
        VROMatrix4f computedJointTransformInMeshCoords = currentMatrix.multiply(localTransform);
        transformsOut[childJointIndex] = computedJointTransformInMeshCoords;

        // Continue going down the skeletal tree
        if (!processSkeletalTransformsForFrame(gModel, skin, animationIndex, subAnimPropertyIndex,
                                               keyFrameTime, childJointIndex, transformsOut)) {
            return false;
        }
    }

    // We have reached the leaf of the skeletal tree.
    return true;
}

void VROGLTFLoader::injectGLTF(std::shared_ptr<VRONode> gltfNode,
                             std::shared_ptr<VRONode> rootNode,
                             std::shared_ptr<VRODriver> driver,
                             std::function<void(std::shared_ptr<VRONode> node, bool success)> onFinish) {
    if (gltfNode) {
        // The top-level glTF Node is a dummy; all of the data is stored in the children, so we
        // simply transfer those children over to the destination node
        for (std::shared_ptr<VRONode> child : gltfNode->getChildNodes()) {
            rootNode->addChildNode(child);
        }

        // Recompute the node's umbrellaBoundingBox and set the atomic rendering properties before
        // we notify the user that their glTF has finished loading
        rootNode->recomputeUmbrellaBoundingBox();
        rootNode->syncAppThreadProperties();
        rootNode->setIgnoreEventHandling(rootNode->getIgnoreEventHandling());
        rootNode->setHoldRendering(true);

        // Don't hold a strong reference to the Node: hydrateAsync stores its callback (and
        // thus all copied lambda variables, including the Node) in VROTexture, which can
        // expose us to strong reference cycles (Node <--> Texture). While the callback is
        // cleaned up after hydration completes, it's possible that hydrate will never
        // complete if the Node is quickly removed.
        std::weak_ptr<VRONode> node_w = rootNode;
        VROModelIOUtil::hydrateAsync(rootNode, [node_w, onFinish] {
            std::shared_ptr<VRONode> node_s = node_w.lock();
            if (node_s) {
                if (onFinish) {
                    onFinish(node_s, true);
                }
                node_s->setHoldRendering(false);
            }
        }, driver);
    }
    else {
        if (onFinish) {
            onFinish(rootNode, false);
        }
    }
}

bool VROGLTFLoader::processScene(const tinygltf::Model &gModel, std::shared_ptr<VRONode> rootNode, const tinygltf::Scene &gScene,
                                 std::shared_ptr<VRODriver> driver) {
    std::shared_ptr<VRONode> sceneNode = std::make_shared<VRONode>();
    sceneNode->setName(gScene.name);

    std::vector<int> gNodeIndexes = gScene.nodes;
    for (int gNodeIndex : gNodeIndexes) {
        // Fail fast if we have failed to process a node in the scene.
        if (!processNode(gModel, sceneNode, gNodeIndex, driver)) {
            return false;
        }
    }

    rootNode->addChildNode(sceneNode);
    return true;
}

bool VROGLTFLoader::processNode(const tinygltf::Model &gModel, std::shared_ptr<VRONode> &parentNode, int gNodeIndex,
                                std::shared_ptr<VRODriver> driver) {
    tinygltf::Node gNode = gModel.nodes[gNodeIndex];

    // Grab the main transformations for this node.
    std::vector<double> gScale = gNode.scale;
    std::vector<double> gPos = gNode.translation;
    std::vector<double> gRot = gNode.rotation;
    VROVector3f pos = gPos.size() > 0 ? VROVector3f(gPos[0], gPos[1], gPos[2]) : VROVector3f();
    VROVector3f scale = gScale.size() > 0 ? VROVector3f(gScale[0], gScale[1], gScale[2]) : VROVector3f(1,1,1);
    VROQuaternion rot = gRot.size() > 0 ? VROQuaternion(gRot[0], gRot[1], gRot[2], gRot[3]) : VROQuaternion();

    // If a transformation matrix is provided, we use that instead.
    std::vector<double> gMat = gNode.matrix;
    if (gMat.size() > 0) {
        std::vector<float> gFloatMatrix;
        for (int i = 0; i < 16; i ++) {
            gFloatMatrix.push_back((float)gMat[i]);
        }
        VROMatrix4f mat = VROMatrix4f(&gFloatMatrix[0]);
        pos = mat.extractTranslation();
        scale = mat.extractScale();
        rot = mat.extractRotation(scale);
    }

    // Finally set the parsed transforms on VRONode.
    std::shared_ptr<VRONode> node = std::make_shared<VRONode>();
    node->setPosition(pos);
    node->setScale(scale);
    node->setRotation(rot);
    node->setName(gNode.name);

    // Process the Geometry for this node, if any.
    // Fail fast if we have failed to process the node's mesh.
    int meshIndex = gNode.mesh;
    if (meshIndex >= 0 && !processMesh(gModel, node, gModel.meshes[meshIndex], driver)) {
        return false;
    }

    // After processing the nodes of this model, process skins if any.
    std::shared_ptr<VROGeometry> geom = node->getGeometry();
    if (geom != nullptr && gNode.skin >=0) {
        _skinMap[gNode.skin]->setSkinnerNode(node);
        geom->setSkinner(_skinMap[gNode.skin]);
        for (const std::shared_ptr<VROMaterial> &material : geom->getMaterials()) {
            material->addShaderModifier(VROBoneUBO::createSkinningShaderModifier(false));
        }
    }

    // Set the animations on this node, if any.
    if (_nodeKeyFrameAnims.find(gNodeIndex) != _nodeKeyFrameAnims.end()) {
        for (int i = 0; i < _nodeKeyFrameAnims[gNodeIndex].size(); i ++) {
            // Add in parallel all animated keyframe properties within this
            // animation, within this node.
            for (auto anim : _nodeKeyFrameAnims[gNodeIndex][i]) {
                node->addAnimation(anim->getName(), anim);
            }
        }
    }

    if (_skinSkeletalAnims.find(gNode.skin) != _skinSkeletalAnims.end()) {
        for (std::shared_ptr<VROSkeletalAnimation> anim : _skinSkeletalAnims[gNode.skin]){
            node->addAnimation(anim->getName(), anim);
        }
    }

    parentNode->addChildNode(node);

    // Recursively process each child node, if any.
    std::vector<int> gNodeChildrenIndexes = gNode.children;
    for (int gNodeIndex : gNodeChildrenIndexes) {
        // Fail fast if we have failed to process a node in the scene.
        if (!processNode(gModel, node, gNodeIndex, driver)) {
            return false;
        }
    }
    return true;
}

bool VROGLTFLoader::processSkinnerInverseBindData(const tinygltf::Model &gModel,
                                                  const tinygltf::Skin &skin,
                                                  std::vector<VROMatrix4f> &invBindTransformsOut) {
    // Process inverseBind Matrices from the gLTF Accessor
    const tinygltf::Accessor &gDataAcessor = gModel.accessors[skin.inverseBindMatrices];
    GLTFTypeComponent gTypeComponent;
    GLTFType gType;
    if (!getComponentType(gDataAcessor, gTypeComponent) || !getComponent(gDataAcessor, gType)) {
        perr("Invalid Animation channel data provided!");
        return false;
    }

    // Calculate the byte stride size if none is provided from the BufferView.
    const tinygltf::BufferView &gIndiceBufferView = gModel.bufferViews[gDataAcessor.bufferView];
    size_t bufferViewStride = gIndiceBufferView.byteStride;
    if (bufferViewStride == 0) {
        int sizeOfSingleElement = getTypeSize(gType) * getComponentTypeSize(gTypeComponent);
        bufferViewStride = sizeOfSingleElement;
    }

    // Determine offsets and data sizes representing the 'window of data' in the buffer
    size_t elementCount = gDataAcessor.count;
    size_t dataOffset = gDataAcessor.byteOffset + gIndiceBufferView.byteOffset;
    size_t dataLength = elementCount * bufferViewStride;

    // Now process that buffer to produce the right output data.
    const tinygltf::Buffer &gBuffer = gModel.buffers[gIndiceBufferView.buffer];
    std::vector<VROMatrix4f> invBindTransforms;
    VROByteBuffer buffer((char *)gBuffer.data.data() + dataOffset, dataLength, false);
    for (int elementIndex = 0; elementIndex < elementCount; elementIndex++) {

        // Set the buffer position to begin at each element index - Ex: Each Mat4.
        buffer.setPosition((elementIndex * bufferViewStride));

        // For the current element, cycle through each of its float or type component
        float invBindMatrix[16];
        for (int componentCount = 0; componentCount < 16; componentCount ++) {
            if (gTypeComponent == GLTFTypeComponent::Float) {
                float floatData = buffer.readFloat();
                invBindMatrix[componentCount] = floatData;
            } else {
                pwarn("Invalid element type in Animation Inverse Matrix Data: %d", gTypeComponent);
                return false;
            }
        }

        VROMatrix4f mat(invBindMatrix);
        invBindTransforms.push_back(mat);
    }
    invBindTransformsOut = invBindTransforms;
    return true;
}

bool VROGLTFLoader::processMesh(const tinygltf::Model &gModel, std::shared_ptr<VRONode> &rootNode, const tinygltf::Mesh &gMesh,
                                std::shared_ptr<VRODriver> driver) {
    if (gMesh.primitives.size() <=0) {
        perr("GTLF requires mesh data to contain at least one primitive!");
        return false;
    }

    // Prepare our vec of elements (vertex indices) and sources (vertex attributes) to be parsed.
    std::vector<std::shared_ptr<VROGeometrySource>> sources;
    std::vector<std::shared_ptr<VROGeometryElement>> elements;
    std::vector<std::shared_ptr<VROMaterial>> materials;
    std::map<int, std::shared_ptr<VROMorpher>> morphers;

    // A single mesh may contain more than one type of primitive type to be drawn. Cycle through them here.
    const std::vector<tinygltf::Primitive> &gPrimitives = gMesh.primitives;
    for (tinygltf::Primitive gPrimitive : gPrimitives) {

        // Grab vertex indexing information needed for creating meshes.
        bool successVertex = processVertexElement(gModel, gPrimitive, elements);
        bool successAttributes = processVertexAttributes(gModel, gPrimitive.attributes, sources, elements.size() - 1, driver);
        processTangent(elements, sources, elements.size() - 1);
        
        if (!successVertex || !successAttributes) {
            pwarn("Failed to process mesh %s.", gMesh.name.c_str());
            return false;
        }

        // Grab the material pertaining to this primitive in this mesh.
        int gMatIndex = gPrimitive.material;
        std::shared_ptr<VROMaterial> material = nullptr;
        if (gMatIndex >= 0) {
            const tinygltf::Material &gMat = gModel.materials[gMatIndex];
            material = getMaterial(gModel, gMat);
        }

        // Process Morph targets for each primitive.
        if (!processMorphTargets(gModel, gMesh, gPrimitive, material, sources, elements, morphers, driver)) {
            pwarn("Failed to process morph target for mesh %s.", gMesh.name.c_str());
            return false;
        }

        if (material != nullptr) {
            materials.push_back(material);
        }
    }

    // Apply a default material if none has been specified.
    if (materials.size() == 0) {
        materials.push_back(std::make_shared<VROMaterial>());
    }

    // Finally construct our geometry with the processed vertex and attribute data.
    std::shared_ptr<VROGeometry> geometry = std::make_shared<VROGeometry>(sources, elements);
    
    geometry->setName(gMesh.name);
    rootNode->setGeometry(geometry);
    geometry->setMaterials(materials);
    geometry->setMorphers(morphers);
    return true;
}

void VROGLTFLoader::processTangent(std::vector<std::shared_ptr<VROGeometryElement>> &elements,
                                   std::vector<std::shared_ptr<VROGeometrySource>> &sources,
                                   size_t geoElementIndex) {
    // Determine if tangent data is missing and thus needs to be calculated.
    std::shared_ptr<VROGeometrySource> pos = nullptr;
    std::shared_ptr<VROGeometrySource> texcoord = nullptr;
    std::shared_ptr<VROGeometrySource> normal = nullptr;
    std::shared_ptr<VROGeometrySource> tangent = nullptr;

    for (auto &source : sources) {
        if (source->getGeometryElementIndex() != geoElementIndex) {
            continue;
        }

        VROGeometrySourceSemantic semantic = source->getSemantic();
        if (semantic == VROGeometrySourceSemantic::Vertex) {
            pos = source;
        } else if (semantic == VROGeometrySourceSemantic::Normal) {
            normal = source;
        } else if (semantic == VROGeometrySourceSemantic::Texcoord) {
            texcoord = source;
        } else if (semantic == VROGeometrySourceSemantic::Tangent) {
            tangent = source;
        }
    }

    // Return if we already have tangent data.
    if (tangent != nullptr) {
        return;
    }

    // Else, to calculate tangent, we MUST have positional, texcoord and normal data.
    if (normal == nullptr || pos == nullptr || texcoord == nullptr) {
        pwarn("Unable to generate missing tangents for this model");
        return;
    }

    std::vector<VROVector3f> posArray;
    pos->processVertices([&posArray](int index, VROVector4f vertex) {
        posArray.push_back(VROVector3f(vertex.x, vertex.y, vertex.z));
    });

    std::vector<VROVector3f> normArray;
    normal->processVertices([&normArray](int index, VROVector4f vertex) {
        normArray.push_back(VROVector3f(vertex.x, vertex.y, vertex.z));
    });

    std::vector<VROVector3f> texCoordArray;
    texcoord->processVertices([&texCoordArray](int index, VROVector4f vertex) {
        texCoordArray.push_back(VROVector3f(vertex.x, vertex.y, vertex.z));
    });

    std::vector<int> elementIndicesArray;
    std::shared_ptr<VROGeometryElement> targetedElement = elements[geoElementIndex];
    targetedElement->processIndices([&elementIndicesArray](int index, int indexRead) {
        elementIndicesArray.push_back(indexRead);
    });

    // Generate the tangents for this model given the attributes for this element index.
    std::vector<VROVector4f> generatedTangents;
    regenerateTangent(posArray, normArray, texCoordArray, elementIndicesArray, generatedTangents);
    if (generatedTangents.size() <= 0) {
        pwarn("Unable to generate tangents for this model");
        return;
    }

    // Finally store the data back into a Tangent geometry source.
    int sizeOfTangent = 4;
    int vertexSize = pos->getVertexCount();
    float *dataOut = new float[vertexSize * sizeOfTangent];
    for (int i = 0, j = 0; i < vertexSize; i++, j += sizeOfTangent) {
        dataOut[j]     = generatedTangents[i].x;
        dataOut[j + 1] = generatedTangents[i].y;
        dataOut[j + 2] = generatedTangents[i].z;
        dataOut[j + 3] = generatedTangents[i].w;
    }

    int sizeOfSingleTangent = getTypeSize(GLTFType::Vec4) * getComponentTypeSize(GLTFTypeComponent::Float);
    std::shared_ptr<VROData> indexData = std::make_shared<VROData>((void *) dataOut,
                                        vertexSize * sizeOfSingleTangent,
                                        VRODataOwnership::Move);
    tangent = std::make_shared<VROGeometrySource>(indexData,
                                        VROGeometrySourceSemantic::Tangent,
                                        vertexSize,
                                        true,
                                        getTypeSize(GLTFType::Vec4),
                                        getComponentTypeSize(GLTFTypeComponent::Float),
                                        0,
                                        sizeOfSingleTangent);
    tangent->setGeometryElementIndex((int) geoElementIndex);
    sources.push_back(tangent);
    return;
}

void VROGLTFLoader::regenerateTangent(std::vector<VROVector3f> &posArray,
                                      std::vector<VROVector3f> &normArray,
                                      std::vector<VROVector3f> &texCoordArray,
                                      std::vector<int> &elementIndicesArray,
                                      std::vector<VROVector4f> &generatedTangents) {
    int vertexSize = (int) posArray.size();
    // Sanity check.
    if (normArray.size() != vertexSize
        || texCoordArray.size() != vertexSize) {
        pwarn("Unable to missing generate tangents for this model - vertex count does not match.");
        return;
    }

    VROVector3f *tan1 = new VROVector3f[vertexSize * 2];
    VROVector3f *tan2 = tan1 + vertexSize;

    // For each triangle, compute the tangent and bitangent
    for (size_t i = 0; i < elementIndicesArray.size(); i += 3) {
        int i1 = elementIndicesArray[i + 0];
        int i2 = elementIndicesArray[i + 1];
        int i3 = elementIndicesArray[i + 2];

        VROVector3f &var1 = posArray[i1];
        VROVector3f &var2 = posArray[i2];
        VROVector3f &var3 = posArray[i3];

        VROVector3f v1(var1.x, var1.y, var1.z);
        VROVector3f v2(var2.x, var2.y, var2.z);
        VROVector3f v3(var3.x, var3.y, var3.z);

        VROVector3f &texcoord1 = texCoordArray[i1];
        VROVector3f &texcoord2 = texCoordArray[i2];
        VROVector3f &texcoord3 = texCoordArray[i3];

        VROVector3f w1(texcoord1.x, texcoord1.y, 0);
        VROVector3f w2(texcoord2.x, texcoord2.y, 0);
        VROVector3f w3(texcoord3.x, texcoord3.y, 0);

        float x1 = v2.x - v1.x;
        float x2 = v3.x - v1.x;
        float y1 = v2.y - v1.y;
        float y2 = v3.y - v1.y;
        float z1 = v2.z - v1.z;
        float z2 = v3.z - v1.z;

        float s1 = w2.x - w1.x;
        float s2 = w3.x - w1.x;
        float t1 = w2.y - w1.y;
        float t2 = w3.y - w1.y;

        float r = 1.0f / (s1 * t2 - s2 * t1);
        VROVector3f sdir((t2 * x1 - t1 * x2) * r, (t2 * y1 - t1 * y2) * r, (t2 * z1 - t1 * z2) * r);
        VROVector3f tdir((s1 * x2 - s2 * x1) * r, (s1 * y2 - s2 * y1) * r, (s1 * z2 - s2 * z1) * r);

        // ADD the tangent to the existing value; this way we average across all triangles
        // that share this vertex. Note we do not normalize, and that is intentional: we
        // want larger triangles to have a bigger "impact" than smaller triangles
        tan1[i1] += sdir;
        tan1[i2] += sdir;
        tan1[i3] += sdir;

        tan2[i1] += tdir;
        tan2[i2] += tdir;
        tan2[i3] += tdir;
    }

    VROVector3f *tan3 = tan1 + vertexSize;
    for (size_t i = 0; i < vertexSize; i++) {
        VROVector3f n = { normArray[i].x, normArray[i].y, normArray[i].z };
        VROVector3f t = tan1[i];

        // Gram-Schmidt orthogonalize
        VROVector3f tangent = (t - n * n.dot(t)).normalize();

        // Calculate handedness
        float handedness = (n.cross(t).dot(tan3[i]) < 0.0F) ? -1.0F : 1.0F;

        // Ensure that tangent is valid before saving it.
        float magnitude = tangent.magnitude();
        if (!isnan(magnitude) && !isinf(magnitude)) {
            generatedTangents.push_back({tangent.x, tangent.y, tangent.z, handedness});
            continue;
        }

        // Else, generate a default tangent with perpendicular assumptions.
        VROVector3f c1 = n.cross(VROVector3f(0,0,1));
        VROVector3f c2 = n.cross(VROVector3f(0,1,0));
        VROVector3f tangent2;
        if (c1.magnitude() > c2.magnitude()) {
            tangent2 = c1;
        } else {
            tangent2 = c2;
        }

        tangent = tangent.normalize();
        generatedTangents.push_back({tangent2.x, tangent2.y, tangent2.z, -1.0});
    }

    delete[] tan1;
}

bool VROGLTFLoader::processVertexElement(const tinygltf::Model &gModel,
                                         const tinygltf::Primitive &gPrimitive,
                                         std::vector<std::shared_ptr<VROGeometryElement>> &elements) {
    // Grab primitive type to be drawn for this geometry.
    VROGeometryPrimitiveType primitiveType;
    if (!getPrimitiveType(gPrimitive.mode, primitiveType)) {
        return false;
    }

    // Grab the vertex indices for this primitive.
    int gPrimitiveIndicesIndex = gPrimitive.indices;
    if (gPrimitiveIndicesIndex < 0) {
        // Fallback to glDrawArrays if no indexed vertices are provided.
        // TODO VIRO-3664: Support Draw Arrays for Viro Geometry in the main render pass.
        pwarn("Models requiring glDrawArray functionality are not yet supported");
        return false;
    }

    // Grab the accessor that maps to a bufferView through which to view the data buffer
    // representing this geometry's indexed vertices.
    const tinygltf::Accessor &gIndicesAccessor = gModel.accessors[gPrimitiveIndicesIndex];
    GLTFTypeComponent gTypeComponent;
    GLTFType gType;
    if (!getComponentType(gIndicesAccessor, gTypeComponent) || !getComponent(gIndicesAccessor, gType)) {
        return false;
    }

    // Warn here if the indexed vertex data is NOT of the proper type expected by GLTF for vertex indexing.
    if (gType != GLTFType::Scalar
        && gTypeComponent != GLTFTypeComponent::UnsignedByte
        && gTypeComponent != GLTFTypeComponent::UnsignedInt
        && gTypeComponent != GLTFTypeComponent::UnsignedShort
        && gTypeComponent != GLTFTypeComponent::Short) {
        perror("Unsupported primitive type provided for GLTF vertex indexes");
        return false;
    }

    // Calculate the byte stride size if none is provided from the BufferView.
    const tinygltf::BufferView &gIndiceBufferView = gModel.bufferViews[gIndicesAccessor.bufferView];
    size_t bufferViewStride = gIndiceBufferView.byteStride;
    if (bufferViewStride == 0) {
        int sizeOfSingleElement = getTypeSize(gType) * getComponentTypeSize(gTypeComponent);
        bufferViewStride = sizeOfSingleElement;
    }

    // Determine offsets and data sizes representing the indexed vertices's 'window of data' in the buffer
    int primitiveCount = VROGeometryUtilGetPrimitiveCount((int) gIndicesAccessor.count, primitiveType);
    size_t elementCount = gIndicesAccessor.count;
    size_t dataOffset = gIndicesAccessor.byteOffset + gIndiceBufferView.byteOffset;
    size_t dataLength = elementCount *  bufferViewStride;

    // Finally, grab the raw indexed vertex data from the buffer to be created with VROGeometryElement
    const tinygltf::Buffer &gBuffer = gModel.buffers[gIndiceBufferView.buffer];
    std::shared_ptr<VROData> data = std::make_shared<VROData>((void *)gBuffer.data.data(),
                                                              dataLength,
                                                              dataOffset);
    std::shared_ptr<VROGeometryElement> element
            = std::make_shared<VROGeometryElement>(data,
                                                   primitiveType,
                                                   primitiveCount,
                                                   getComponentTypeSize(gTypeComponent),
                                                   gTypeComponent != GLTFTypeComponent::UnsignedByte &&
                                                   gTypeComponent != GLTFTypeComponent::UnsignedShort);
    elements.push_back(element);
    return true;
}

bool VROGLTFLoader::processVertexAttributes(const tinygltf::Model &gModel,
                                            std::map<std::string, int> &gAttributes,
                                            std::vector<std::shared_ptr<VROGeometrySource>> &sources,
                                            size_t geoElementIndex,
                                            std::shared_ptr<VRODriver> driver) {
    if (gAttributes.size() <= 0) {
        return false;
    }

    // Iterate through each Vertex Attribute (Position / Normals / etc) to parse its data
    for (auto const& gAttribute : gAttributes) {
        std::string attributeName = gAttribute.first;
        int attributeAccessorIndex = gAttribute.second;

        // Ensure we only parse valid attributes, gracefully skip over the ones we do not yet support
        VROGeometrySourceSemantic attributeType = getGeometryAttribute(attributeName);
        if (attributeType == VROGeometrySourceSemantic::Invalid) {
            continue;
        }

        // Grab the accessor that maps to a bufferView through which to access the data buffer
        // representing this attribute's raw data.
        const tinygltf::Accessor &gAttributeAccesor = gModel.accessors[attributeAccessorIndex];
        GLTFType gType;
        GLTFTypeComponent gTypeComponent;
        if (!getComponentType(gAttributeAccesor, gTypeComponent) || !getComponent(gAttributeAccesor, gType)) {
            return false;
        }
        
        // Determine the offsets and data sizes representing the 'window of data' for this attribute in the buffer
        const tinygltf::BufferView gIndiceBufferView = gModel.bufferViews[gAttributeAccesor.bufferView];
        
        std::shared_ptr<VROGeometrySource> source;

        if (attributeType != VROGeometrySourceSemantic::BoneWeights) {
            size_t bufferViewOffset = gIndiceBufferView.byteOffset;
            size_t bufferViewTotalSize = gIndiceBufferView.byteLength;
            
            // Process and cache the attribute data to be used by the VROGeometrySource associated with
            // this attribute. If we've already been processed (cached) it before, simply grab it.
            std::string key = VROStringUtil::toString(gAttributeAccesor.bufferView);
            std::shared_ptr<VROVertexBuffer> vbo;
            
            auto it = VROGLTFLoader::_dataCache.find(key);
            if (it == VROGLTFLoader::_dataCache.end()) {
                const tinygltf::Buffer &gbuffer = gModel.buffers[gIndiceBufferView.buffer];
                vbo = driver->newVertexBuffer(std::make_shared<VROData>((void *) gbuffer.data.data(), bufferViewTotalSize, bufferViewOffset));
                VROGLTFLoader::_dataCache[key] = vbo;
            } else {
                vbo = it->second;
            }
            source = buildGeometrySource(attributeType, gType, gTypeComponent, gAttributeAccesor, gIndiceBufferView, vbo);
            
        } else {
            const tinygltf::Buffer &gBuffer = gModel.buffers[gIndiceBufferView.buffer];
            source = buildBoneWeightSource(gType, gTypeComponent, gAttributeAccesor, gIndiceBufferView, gBuffer);
        }

        // Because GLTF can have VROGeometryElements that corresponds to different sets of VROGeometrySources,
        // the render needs to be notified of this element-to-source mapping, so that the correct vertex
        // indices are bounded to and pointed by the right set of vertex attributes. Thus, we set the
        // correspondingly mapped VROGeometryElement index here to preserve that mapping.
        source->setGeometryElementIndex((int) geoElementIndex);
        sources.push_back(source);
    }

    return true;
}

bool VROGLTFLoader::processMorphTargets(const tinygltf::Model &gModel,
                                        const tinygltf::Mesh &gMesh,
                                        const tinygltf::Primitive &gPrimitive,
                                        std::shared_ptr<VROMaterial> &mat,
                                        std::vector<std::shared_ptr<VROGeometrySource>> &sources,
                                        std::vector<std::shared_ptr<VROGeometryElement>> &elements,
                                        std::map<int, std::shared_ptr<VROMorpher>> &morphers,
                                        std::shared_ptr<VRODriver> driver) {
    // Return early if we have no morph data to process for this geometry.
    if (gPrimitive.targets.size() <= 0) {
        return true;
    }

    // Error out if the mesh does not contain the material required for
    // implementing morph target shaders.
    if (mat == nullptr) {
        return false;
    }

    // Create a base set of geometry sources, required by VROMorpher.
    int elementIndex = (int) (elements.size() - 1);
    std::vector<std::shared_ptr<VROGeometrySource>> baseSources;
    for (std::shared_ptr<VROGeometrySource> &src : sources) {
        if (src->getGeometryElementIndex() == elementIndex) {
            baseSources.push_back(src);
        }
    }

    // Create our VROMorpher class with the base set of geometry sources.
    std::shared_ptr<VROMorpher> morpher = std::make_shared<VROMorpher>(baseSources, mat);

    // Next, grab the morph targets that we'll be applying onto our base geometry in VROMorpher.
    // We parse each raw gLTF morph target below, save it in our VROMorpher, and refer to it by
    // it's name / key.
    for (int targetIndex = 0; targetIndex < gPrimitive.targets.size(); targetIndex ++) {
        std::vector<std::shared_ptr<VROGeometrySource>> morphTargetSources;
        std::map<std::string, int> gAttributes = gPrimitive.targets[targetIndex];
        if (!processVertexAttributes(gModel, gAttributes, morphTargetSources, elements.size() -1, driver)) {
            pwarn("Invalid Attribute found for morph target!");
            return false;
        }

        // Quick sanity check to ensure we have the proper morphing data type.
        for (std::shared_ptr<VROGeometrySource> source : morphTargetSources) {
            if (source->getSemantic() != VROGeometrySourceSemantic::Vertex &&
                source->getSemantic() != VROGeometrySourceSemantic::Tangent &&
                source->getSemantic() != VROGeometrySourceSemantic::Normal) {
                pwarn("Unsupported Attribute found for morph target!");
                return false;
            }
        }

        // Grab the rest of the target's properties.
        std::string key = getMorphTargetName(gModel, gPrimitive, targetIndex);
        float weight = 0.0;
        if (targetIndex < gMesh.weights.size()) {
            weight = gMesh.weights[targetIndex];
        }

        // Add the new target back to the VROMorpher.
        morpher->addTarget(morphTargetSources, key, weight);
    }

    morphers[elementIndex] = morpher;
    return true;
}

std::string VROGLTFLoader::getMorphTargetName(const tinygltf::Model &gModel,
                                              const tinygltf::Primitive &gPrimitive,
                                              int targetIndex) {
    std::string key = VROStringUtil::toString(targetIndex);

    // Iterate through the property accessors of the mesh target to grab it's name.
    std::map<std::string, int> gAttributes = gPrimitive.targets[targetIndex];
    if (gAttributes.size() > 0) {
        for (auto const& gAttribute : gAttributes) {
            int attributeAccessorIndex = gAttribute.second;
            const tinygltf::Accessor &gAttributeAccesor = gModel.accessors[attributeAccessorIndex];
            std::string name = gAttributeAccesor.name;

            // Break out as all accessors will have the same name.
            if (name.size() > 0) {
                key = name;
                break;
            }
        }
    }

    return key;
}

std::shared_ptr<VROGeometrySource> VROGLTFLoader::buildGeometrySource(VROGeometrySourceSemantic attributeType,
                                                                      GLTFType gType,
                                                                      GLTFTypeComponent gTypeComponent,
                                                                      const tinygltf::Accessor &gAttributeAccesor,
                                                                      const tinygltf::BufferView &gIndiceBufferView,
                                                                      std::shared_ptr<VROVertexBuffer> vbo) {
    bool isFloat = gTypeComponent == GLTFTypeComponent::Float;
    size_t attributeAccessorOffset = gAttributeAccesor.byteOffset;
    
    // Calculate the byte stride size if none is provided from the BufferView
    size_t bufferViewStride = gIndiceBufferView.byteStride;
    if (bufferViewStride == 0) {
        int sizeOfSingleElement = getTypeSize(gType) * getComponentTypeSize(gTypeComponent);
        bufferViewStride = sizeOfSingleElement;
    }
    
    // Build the GeometrySource
    int elementCount = (int) gAttributeAccesor.count;
    return std::make_shared<VROGeometrySource>(vbo,
                                               attributeType,
                                               elementCount,
                                               isFloat,
                                               getTypeSize(gType),
                                               getComponentTypeSize(gTypeComponent),
                                               attributeAccessorOffset,
                                               bufferViewStride);
}

std::shared_ptr<VROGeometrySource> VROGLTFLoader::buildBoneWeightSource(GLTFType gType,
                                                                        GLTFTypeComponent gTypeComponent,
                                                                        const tinygltf::Accessor &gAttributeAccesor,
                                                                        const tinygltf::BufferView &gIndiceBufferView,
                                                                        const tinygltf::Buffer &gbuffer) {
    bool isFloat = gTypeComponent == GLTFTypeComponent::Float;
    size_t bufferViewOffset = gIndiceBufferView.byteOffset;
    size_t bufferViewTotalSize = gIndiceBufferView.byteLength;
    
    // Calculate the byte stride size if none is provided from the BufferView.
    size_t bufferViewStride = gIndiceBufferView.byteStride;
    if (bufferViewStride == 0) {
        int sizeOfSingleElement = getTypeSize(gType) * getComponentTypeSize(gTypeComponent);
        bufferViewStride = sizeOfSingleElement;
    }
    
    // gLTF requires the manual normalization of weighted bone attributes. As such,
    // we process them here before constructing our VROGeometrySource.
    VROByteBuffer buffer((char *) gbuffer.data.data() + bufferViewOffset, bufferViewTotalSize, false);
    
    // Parse the gLTF buffers for the weight of each bone and normalize them.
    // The normalized data is stored in dataOut.
    int sizeOfSingleBoneWeight = getTypeSize(gType) * getComponentTypeSize(gTypeComponent);
    float *dataOut = new float[sizeOfSingleBoneWeight * gAttributeAccesor.count]();
    for (int elementIndex = 0; elementIndex < gAttributeAccesor.count; elementIndex++) {
        int elementIndex4 = elementIndex << 2;
        // For the current element, cycle through each of its float or type component
        // and convert them into a float through the math conversions required by gLTF.
        buffer.setPosition(elementIndex * bufferViewStride);
        std::vector<float> weight;
        for (int componentCount = 0; componentCount < getTypeSize(gType); componentCount++) {
            if (gTypeComponent == GLTFTypeComponent::Float) {
                float floatData = buffer.readFloat();
                weight.push_back(floatData);
            } else if (gTypeComponent == GLTFTypeComponent::UnsignedByte) {
                unsigned uByteData = buffer.readUnsignedByte();
                float point = uByteData / 255.0F;
                weight.push_back(point);
            } else if (gTypeComponent == GLTFTypeComponent::UnsignedShort) {
                unsigned short uShortData = buffer.readUnsignedShort();
                float point = uShortData / 65535.0F;
                weight.push_back(point);
            } else {
                perr("Invalid weighted bone data provided for the 3D glTF skinner.");
                return {};
            }
        }
        
        float totalWeight = weight[0] + weight[1] + weight[2] + weight[3];
        VROVector4f normalizedWeight;
        VROVector4f(weight[0], weight[1], weight[2], weight[3]).scale(1/totalWeight, &normalizedWeight);
        dataOut[elementIndex4]     = normalizedWeight.x;
        dataOut[elementIndex4 + 1] = normalizedWeight.y;
        dataOut[elementIndex4 + 2] = normalizedWeight.z;
        dataOut[elementIndex4 + 3] = normalizedWeight.w;
    }
    
    // Finally create our geometry sources with the normalized data.
    std::shared_ptr<VROData> indexData = std::make_shared<VROData>((void *) dataOut,
                                                                   sizeOfSingleBoneWeight * gAttributeAccesor.count,
                                                                   VRODataOwnership::Move);
    return std::make_shared<VROGeometrySource>(indexData,
                                               VROGeometrySourceSemantic::BoneWeights,
                                               gAttributeAccesor.count,
                                               isFloat,
                                               getTypeSize(gType),
                                               getComponentTypeSize(gTypeComponent),
                                               0,
                                               sizeOfSingleBoneWeight);
}

std::shared_ptr<VROMaterial> VROGLTFLoader::getMaterial(const tinygltf::Model &gModel, const tinygltf::Material &gMat) {
    std::shared_ptr<VROMaterial> vroMat = std::make_shared<VROMaterial>();
    tinygltf::ParameterMap gAdditionalMap = gMat.additionalValues;

    // Process PBR values from the given tinyGLTF material into our VROMaterial, if any.
    processPBR(gModel, vroMat, gMat);

    // Process Normal textures
    std::shared_ptr<VROTexture> normalTexture = getTexture(gModel, gAdditionalMap, "normalTexture", false);
    if (normalTexture != nullptr) {
        vroMat->getNormal().setTexture(normalTexture);
    }

    // Process Occlusion Textures
    std::shared_ptr<VROTexture> occlusionTexture = getTexture(gModel, gAdditionalMap, "occlusionTexture", false);
    if (occlusionTexture != nullptr) {
        vroMat->getAmbientOcclusion().setTexture(occlusionTexture);
    }

    // Process GLTF transparency modes
    std::string mode = "OPAQUE";
    if (gAdditionalMap.find("alphaMode") != gAdditionalMap.end()) {
        mode = gAdditionalMap["alphaMode"].string_value;
    }

    if (VROStringUtil::strcmpinsensitive(mode, "OPAQUE")) {
        vroMat->setTransparencyMode(VROTransparencyMode::RGBZero);
    } else if (VROStringUtil::strcmpinsensitive(mode, "MASK")) {
        // TODO VIRO-3684: Implement Transparent Masks, fallback to Alpha transparency for now.
        vroMat->setTransparencyMode(VROTransparencyMode::AOne);
    } else if (VROStringUtil::strcmpinsensitive(mode, "BLEND")) {
        vroMat->setTransparencyMode(VROTransparencyMode::AOne);
    }

    // TODO VIRO-3683: Implement GLTF Emissive Maps
    vroMat->setName(gMat.name);
    return vroMat;
}

void VROGLTFLoader::processPBR(const tinygltf::Model &gModel, std::shared_ptr<VROMaterial> &vroMat, const tinygltf::Material &gMat) {
    std::map<std::string, tinygltf::Parameter> gPbrMap = gMat.pbrValues;
    if (gPbrMap.size() <= 0) {
        vroMat->setLightingModel(VROLightingModel::Lambert);
        return;
    }

    // Process PBR base color, defaults to white.
    VROVector4f color = VROVector4f(1, 1, 1, 1);
    if (gPbrMap.find("baseColorFactor") != gPbrMap.end()) {
        std::array<double, 4> vec4_color = gPbrMap["baseColorFactor"].ColorFactor();
        color = VROVector4f(vec4_color[0], vec4_color[1], vec4_color[2], vec4_color[3]);
    }
    vroMat->getDiffuse().setColor(color);

    // Process PBR metal factor, defaults to fully metallic.
    double metallicFactor = 1;
    if (gPbrMap.find("metallicFactor") != gPbrMap.end()) {
        metallicFactor = gPbrMap["metallicFactor"].Factor();
    }
    vroMat->getMetalness().setIntensity(metallicFactor);
    
    // Process PBR roughness factor, defaults to fully rough.
    double roughnessFactor = 1;
    if (gPbrMap.find("roughnessFactor") != gPbrMap.end()) {
        roughnessFactor = gPbrMap["roughnessFactor"].Factor();
    }
    vroMat->getRoughness().setIntensity(roughnessFactor);

    // Process a metallic / roughness texture if any, where metalness values are sampled from the
    // B channel and roughness values are sampled from the G channel.
    std::shared_ptr<VROTexture> metallicRoughnessTexture = getTexture(gModel, gPbrMap, "metallicRoughnessTexture", false);
    if (metallicRoughnessTexture != nullptr) {
        vroMat->getMetalness().setTexture(metallicRoughnessTexture);
        vroMat->getRoughness().setTexture(metallicRoughnessTexture);
    }
    else {
        vroMat->getMetalness().setColor({ (float) metallicFactor, 1.0, 1.0, 1.0 });
        vroMat->getRoughness().setColor({ (float) roughnessFactor, 1.0, 1.0, 1.0 });
    }

    // Grab the base color texture in sRGB space.
    std::shared_ptr<VROTexture> baseColorTexture = getTexture(gModel, gPbrMap, "baseColorTexture", true);
    if (baseColorTexture != nullptr) {
        vroMat->getDiffuse().setTexture(baseColorTexture);
    }
    vroMat->setLightingModel(VROLightingModel::PhysicallyBased);
}

std::shared_ptr<VROTexture> VROGLTFLoader::getTexture(const tinygltf::Model &gModel, std::map<std::string, tinygltf::Parameter> gPropMap,
                                                      std::string targetedTextureName, bool srgb) {
    if (gPropMap.find(targetedTextureName) == gPropMap.end()) {
        return nullptr;
    }

    int index = gPropMap[targetedTextureName].TextureIndex();
    if (index < 0) {
        return nullptr;
    }

    tinygltf::Texture gTexture = gModel.textures[index];
    return getTexture(gModel, gTexture, srgb);
}

std::shared_ptr<VROTexture> VROGLTFLoader::getTexture(const tinygltf::Model &gModel, const tinygltf::Texture &gTexture, bool srgb){
    std::shared_ptr<VROTexture> texture = nullptr;
    int imageIndex = gTexture.source;
    if (imageIndex < 0){
        perr("Attempted to grab an invalid GTLF texture source.");
        return nullptr;
    }

    // Return the texture if we had already previously processed and cached this image.
    if (VROGLTFLoader::_textureCache.find(VROStringUtil::toString(imageIndex)) != VROGLTFLoader::_textureCache.end()){
        std::string key = VROStringUtil::toString(imageIndex);
        return VROGLTFLoader::_textureCache[key];
    }

    // Grab the GLTF image data of for this texture.
    tinygltf::Image gImg = gModel.images[imageIndex];
    std::string imgName = gImg.name;

    // Decode the GLTF image data / raw bytes into a VROImage data.
    std::vector<unsigned char> data = gImg.rawByteVec;
    std::shared_ptr<VROImage> image = VROPlatformLoadImageWithBufferedData(data, VROTextureInternalFormat::RGBA8);
    if (image == nullptr){
        perr("Error when parsing texture for image %s.", imgName.c_str());
        return nullptr;
    }

    // Use the VROImage data to create a VROTexture, with parsed GLTF Sampler properties.
    texture = std::make_shared<VROTexture>(srgb, VROMipmapMode::Runtime, image);
    int samplerIndex = gTexture.sampler;
    if (samplerIndex >=0) {
        tinygltf::Sampler sampler = gModel.samplers[samplerIndex];
        texture->setWrapS(getWrappingMode(sampler.wrapS));
        texture->setWrapT(getWrappingMode(sampler.wrapT));
        texture->setMagnificationFilter(getFilterMode(sampler.magFilter));
        texture->setMinificationFilter(getFilterMode(sampler.minFilter));
    } else {
        texture->setWrapS(VROWrapMode::Repeat);
        texture->setWrapT(VROWrapMode::Repeat);
        texture->setMagnificationFilter(VROFilterMode::Linear);
        texture->setMinificationFilter(VROFilterMode::Linear);
    }

    // Cache a copy of the created texture as other elements may also refer to it.
    std::string key = VROStringUtil::toString(imageIndex);
    VROGLTFLoader::_textureCache[key] = texture;
    return texture;
}

VROMatrix4f VROGLTFLoader::getTransformOfNode(const tinygltf::Model &gModel, int nodeIndex) {
    tinygltf::Node gNode = gModel.nodes[nodeIndex];

    // Grab the main transformations for this node.
    std::vector<double> gScale = gNode.scale;
    std::vector<double> gPos = gNode.translation;
    std::vector<double> gRot = gNode.rotation;
    VROVector3f pos = gPos.size() > 0 ? VROVector3f(gPos[0], gPos[1], gPos[2]) : VROVector3f();
    VROVector3f scale = gScale.size() > 0 ? VROVector3f(gScale[0], gScale[1], gScale[2]) : VROVector3f(1,1,1);
    VROQuaternion rot = gRot.size() > 0 ? VROQuaternion(gRot[0], gRot[1], gRot[2], gRot[3]) : VROQuaternion();

    // If a transformation matrix is provided, we use that instead.
    std::vector<double> gMat = gNode.matrix;
    if (gMat.size() > 0) {
        std::vector<float> gFloatMatrix;
        for (int i = 0; i < 16; i ++) {
            gFloatMatrix.push_back((float)gMat[i]);
        }
        VROMatrix4f mat = VROMatrix4f(&gFloatMatrix[0]);
        pos = mat.extractTranslation();
        scale = mat.extractScale();
        rot = mat.extractRotation(scale);
    }

    VROMatrix4f localTransform;
    localTransform.scale(scale.x, scale.y, scale.z);
    localTransform.rotate(rot);
    localTransform.translate(pos);
    return localTransform;
}
